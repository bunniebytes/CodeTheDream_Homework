Some challenges I faced early on was figuring out how to address the multiple authors in the get_books.py program.  I knew I wanted to loop through the information, but I was pulling the information as "driver.find_elements(By.CSS_SELECTOR, "a.author-link")" instead of "result.find_elements(By.CSS_SELECTOR, "a.author-link")".  This led to a lot of confusion on my part.  Once I figured this out things really clicked.

The next challenge I faced was figuring out how to loop through the pages in the optional assignment.  I started to make it too complicated where I was keeping the first part of the program the same but just adding on to it, this resulted in a lot of needing to rewrite the JSON as well as concatinate the dataframe.  That also meant I would have had to keep running checks for them.  Once I stepped away from the code for a night, I realized that I could do all the scraping at once and then write to the JSON and the CSV file at once instead of constantly updating and rewriting.